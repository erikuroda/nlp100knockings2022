{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70. 単語ベクトルの和による特徴量  \n",
    "    問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例$x_i$の特徴ベクトル$xi$を並べた行列$X$と，正解ラベルを並べた行列（ベクトル）$Y$を作成したい．  \n",
    "    $$\n",
    "    X=\n",
    "    \\begin{pmatrix}\n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "    \\cdots \\\\\n",
    "    x_n\n",
    "    \\end{pmatrix}\n",
    "    \\in \\mathbb{R}^{n \\times d}, Y=\n",
    "    \\begin{pmatrix}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    \\cdots \\\\\n",
    "    y_n\n",
    "    \\end{pmatrix}\n",
    "    \\in \\mathbb{N}^n\n",
    "    $$  \n",
    "    ここで，$n$は学習データの事例数であり，$x_i \\in \\mathbb{R}^d$と$y_i \\in \\mathbb{N}$はそれぞれ，$i \\in \\{1, \\dots, n\\}$番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．$\\mathbb{N}_{<4}$で4未満の自然数（0を含む）を表すことにすれば，任意の事例の正解ラベル$y_i$は$y_i \\in \\mathbb{N}_{<4}$で表現できる． 以降では，ラベルの種類数を$L$で表す（今回の分類タスクでは$L=4$である）．  \n",
    "    $i$番目の事例の特徴ベクトル$x_i$は，次式で求める．  \n",
    "    $$\n",
    "    x_i = \\frac{1}{T_i} \\Sigma^{T_i}_{t=1} emb(w_{i,t})\n",
    "    $$\n",
    "    ここで，$i$番目の事例は$T_i$個の（記事見出しの）単語列$(w_{i,1},w_{i,2},\\dots,w_{i,T_i})$から構成され，$emb(w) \\in \\mathbb{R}^d$は単語$w$に対応する単語ベクトル（次元数は$d$）である．すなわち，$i$番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものが$x_i$である．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300次元の単語ベクトルを用いたので，$d=300$である．  \n",
    "    $i$番目の事例のラベル$y_i$は，次のように定義する．\n",
    "    $$\n",
    "    y_i=\n",
    "    \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "    0 & (記事x_iが「ビジネス」カテゴリの場合) \\\\\n",
    "    1 & (記事x_iが「科学技術」カテゴリの場合) \\\\\n",
    "    2 & (記事x_iが「エンターテイメント」カテゴリの場合) \\\\\n",
    "    3 & (記事x_iが「健康」カテゴリの場合)\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "    $$\n",
    "    なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．  \n",
    "    以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．  \n",
    "    - 学習データの特徴量行列: $X_{train} \\in \\mathbb{R}^{N_t \\times d}$\n",
    "    - 学習データのラベルベクトル: $Y_{train} \\in \\mathbb{N}^{N_t}$\n",
    "    - 検証データの特徴量行列: $X_{valid} \\in \\mathbb{R}^{N_v \\times d}$\n",
    "    - 検証データのラベルベクトル: $Y_{valid} \\in \\mathbb{N}^{N_v}$\n",
    "    - 評価データの特徴量行列: $X_{test} \\in \\mathbb{R}^{N_e \\times d}$\n",
    "    - 評価データのラベルベクトル: $Y_{test} \\in \\mathbb{N}^{N_e}$  \n",
    "      \n",
    "    なお，$N_t,N_v,N_e$はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text) -> str:\n",
    "    import texthero as hero\n",
    "    clean_text = hero.clean(text, pipeline=[\n",
    "        hero.preprocessing.fillna, \n",
    "        hero.preprocessing.lowercase,\n",
    "        hero.preprocessing.remove_digits, \n",
    "        hero.preprocessing.remove_punctuation, \n",
    "        hero.preprocessing.remove_diacritics, \n",
    "        hero.preprocessing.remove_stopwords\n",
    "    ])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vec(s):\n",
    "    sumvec = np.zeros(300)\n",
    "    words = s.split()\n",
    "    for w in words:\n",
    "        try:\n",
    "            sumvec += wvs.get_vector(w)\n",
    "        except KeyError: continue\n",
    "    return sumvec/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['train','valid','test']:\n",
    "    df = pd.read_table(name+'.txt', header=0, names=['CATEGORY', 'TITLE'])\n",
    "    clean_title = preprocess(df['TITLE'])\n",
    "    X = clean_title.apply(calc_vec)\n",
    "    X = np.array([X.values[i] for i in range(len(X.values))])\n",
    "    Y = df['CATEGORY'].replace({'b':0, 't':1, 'e':2, 'm':3})\n",
    "    np.save(name+'.X', X)\n",
    "    np.save(name+'.Y', Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.backend import gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "71. 単層ニューラルネットワークによる予測  \n",
    "    問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
    "    $$\n",
    "    \\hat{y_1} = softmax(x_1 W), \\\\\n",
    "    \\hat{Y} = softmax(X_{[1:4]}W)\n",
    "    $$\n",
    "    ただし，softmaxはソフトマックス関数，$X_{[1:4]} \\in \\mathbb{R}^{4 \\times d}$は特徴ベクトル$x_1,x_2,x_3,x_4$を縦に並べた行列である．\n",
    "    $$\n",
    "    X_{[1:4]}=\n",
    "    \\begin{pmatrix}\n",
    "    x_1 \\\\\n",
    "    x_2 \\\\\n",
    "    x_3 \\\\\n",
    "    x_4\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "    行列$W \\in \\mathbb{R}^{d \\times L}$は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．なお，$\\hat{y_1} \\in \\mathbb{R}^{L}$は未学習の行列$W$で事例$x_1$を分類したときに，各カテゴリに属する確率を表すベクトルである． 同様に，$\\hat{Y} \\in \\mathbb{R}^{n \\times L}$は，学習データの事例$x_1,x_2,x_3,x_4$について，各カテゴリに属する確率を行列として表現している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load('train.X.npy', allow_pickle=True)\n",
    "label = np.load('train.Y.npy', allow_pickle=True)\n",
    "train_Y = np.identity(4)[label]\n",
    "\n",
    "valid_X = np.load('valid.X.npy', allow_pickle=True)\n",
    "label = np.load('valid.Y.npy', allow_pickle=True)\n",
    "valid_Y = np.identity(4)[label]\n",
    "\n",
    "test_X = np.load('valid.X.npy', allow_pickle=True)\n",
    "label = np.load('valid.Y.npy', allow_pickle=True)\n",
    "test_Y = np.identity(4)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=300, name='input_layer'),\n",
    "    Dense(4, activation='sigmoid', name='dense_layer')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='softmax', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48678702, 0.49742734, 0.4794861 , 0.4472388 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48678702, 0.49742734, 0.47948614, 0.4472388 ],\n",
       "       [0.49579448, 0.5144602 , 0.48260877, 0.48576888],\n",
       "       [0.4953651 , 0.558468  , 0.46711385, 0.47748893],\n",
       "       [0.48919407, 0.5039474 , 0.53616875, 0.49512303]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_X[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72. 損失と勾配の計算  \n",
    "    学習データの事例$x_1$と事例集合$x_1,x_2,x_3,x_4$に対して，クロスエントロピー損失と，行列$W$に対する勾配を計算せよ．なお，ある事例$x_i$に対して損失は次式で計算される．  \n",
    "    $$l_i=−log[事例x_iがy_iに分類される確率]$$  \n",
    "    ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 360ms/step - loss: 1.3767 - accuracy: 0.2500\n",
      "loss : 1.3767322301864624\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=300, name='input_layer'),\n",
    "    Dense(4, activation='sigmoid', name='dense_layer')\n",
    "])\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "loss, acc = model.evaluate(train_X[:4], train_Y[:4])\n",
    "print('loss :', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3767 - accuracy: 0.2500\n",
      "[None, None]\n"
     ]
    }
   ],
   "source": [
    "tensor_x = tf.convert_to_tensor(train_X[:4])\n",
    "tensor_y = tf.convert_to_tensor(train_Y[:4])\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(tensor_x)\n",
    "    loss, acc = model.evaluate(tensor_x, tensor_y)\n",
    "    loss = tf.convert_to_tensor(loss)\n",
    "grads = tape.gradient(loss, model.trainable_weights)\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73. 確率的勾配降下法による学習  \n",
    "    確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列$W$を学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76. チェックポイント\n",
    "    問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoint/',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10672 samples, validate on 1334 samples\n",
      "Epoch 1/150\n",
      "10672/10672 [==============================] - ETA: 0s - loss: 1.2099 - accuracy: 0.6145INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 179us/sample - loss: 1.2099 - accuracy: 0.6145 - val_loss: 1.0855 - val_accuracy: 0.7339\n",
      "Epoch 2/150\n",
      "10112/10672 [===========================>..] - ETA: 0s - loss: 1.0353 - accuracy: 0.7488INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 171us/sample - loss: 1.0332 - accuracy: 0.7496 - val_loss: 0.9819 - val_accuracy: 0.7564\n",
      "Epoch 3/150\n",
      " 9824/10672 [==========================>...] - ETA: 0s - loss: 0.9578 - accuracy: 0.7614INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 129us/sample - loss: 0.9541 - accuracy: 0.7620 - val_loss: 0.9183 - val_accuracy: 0.7594\n",
      "Epoch 4/150\n",
      "10240/10672 [===========================>..] - ETA: 0s - loss: 0.9021 - accuracy: 0.7655INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 125us/sample - loss: 0.8998 - accuracy: 0.7661 - val_loss: 0.8709 - val_accuracy: 0.7616\n",
      "Epoch 5/150\n",
      "10016/10672 [===========================>..] - ETA: 0s - loss: 0.8593 - accuracy: 0.7663INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 100us/sample - loss: 0.8577 - accuracy: 0.7672 - val_loss: 0.8331 - val_accuracy: 0.7624\n",
      "Epoch 6/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.8227 - accuracy: 0.7695INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 129us/sample - loss: 0.8234 - accuracy: 0.7686 - val_loss: 0.8016 - val_accuracy: 0.7661\n",
      "Epoch 7/150\n",
      "10672/10672 [==============================] - 1s 48us/sample - loss: 0.7946 - accuracy: 0.7695 - val_loss: 0.7749 - val_accuracy: 0.7661\n",
      "Epoch 8/150\n",
      "10464/10672 [============================>.] - ETA: 0s - loss: 0.7703 - accuracy: 0.7697INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 106us/sample - loss: 0.7698 - accuracy: 0.7699 - val_loss: 0.7516 - val_accuracy: 0.7669\n",
      "Epoch 9/150\n",
      "10672/10672 [==============================] - 1s 53us/sample - loss: 0.7481 - accuracy: 0.7702 - val_loss: 0.7312 - val_accuracy: 0.7669\n",
      "Epoch 10/150\n",
      "10496/10672 [============================>.] - ETA: 0s - loss: 0.7286 - accuracy: 0.7707INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 94us/sample - loss: 0.7289 - accuracy: 0.7710 - val_loss: 0.7130 - val_accuracy: 0.7676\n",
      "Epoch 11/150\n",
      "10080/10672 [===========================>..] - ETA: 0s - loss: 0.7148 - accuracy: 0.7698INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 110us/sample - loss: 0.7117 - accuracy: 0.7716 - val_loss: 0.6967 - val_accuracy: 0.7691\n",
      "Epoch 12/150\n",
      "10464/10672 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.7736INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 110us/sample - loss: 0.6961 - accuracy: 0.7726 - val_loss: 0.6818 - val_accuracy: 0.7714\n",
      "Epoch 13/150\n",
      "10672/10672 [==============================] - 1s 54us/sample - loss: 0.6820 - accuracy: 0.7735 - val_loss: 0.6682 - val_accuracy: 0.7714\n",
      "Epoch 14/150\n",
      "10560/10672 [============================>.] - ETA: 0s - loss: 0.6689 - accuracy: 0.7743INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 111us/sample - loss: 0.6690 - accuracy: 0.7744 - val_loss: 0.6557 - val_accuracy: 0.7766\n",
      "Epoch 15/150\n",
      "10208/10672 [===========================>..] - ETA: 0s - loss: 0.6574 - accuracy: 0.7771INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 101us/sample - loss: 0.6570 - accuracy: 0.7769 - val_loss: 0.6441 - val_accuracy: 0.7789\n",
      "Epoch 16/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.6460 - accuracy: 0.7785INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 107us/sample - loss: 0.6459 - accuracy: 0.7787 - val_loss: 0.6333 - val_accuracy: 0.7796\n",
      "Epoch 17/150\n",
      " 9632/10672 [==========================>...] - ETA: 0s - loss: 0.6368 - accuracy: 0.7816INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 103us/sample - loss: 0.6356 - accuracy: 0.7815 - val_loss: 0.6233 - val_accuracy: 0.7804\n",
      "Epoch 18/150\n",
      "10208/10672 [===========================>..] - ETA: 0s - loss: 0.6269 - accuracy: 0.7859INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 105us/sample - loss: 0.6260 - accuracy: 0.7853 - val_loss: 0.6140 - val_accuracy: 0.7826\n",
      "Epoch 19/150\n",
      " 9504/10672 [=========================>....] - ETA: 0s - loss: 0.6197 - accuracy: 0.7857INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 98us/sample - loss: 0.6170 - accuracy: 0.7876 - val_loss: 0.6052 - val_accuracy: 0.7856\n",
      "Epoch 20/150\n",
      "10144/10672 [===========================>..] - ETA: 0s - loss: 0.6102 - accuracy: 0.7898INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 103us/sample - loss: 0.6085 - accuracy: 0.7907 - val_loss: 0.5969 - val_accuracy: 0.7886\n",
      "Epoch 21/150\n",
      "10560/10672 [============================>.] - ETA: 0s - loss: 0.6004 - accuracy: 0.7932INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 106us/sample - loss: 0.6005 - accuracy: 0.7933 - val_loss: 0.5891 - val_accuracy: 0.7916\n",
      "Epoch 22/150\n",
      " 9760/10672 [==========================>...] - ETA: 0s - loss: 0.5956 - accuracy: 0.7945INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 101us/sample - loss: 0.5929 - accuracy: 0.7974 - val_loss: 0.5818 - val_accuracy: 0.7939\n",
      "Epoch 23/150\n",
      " 9728/10672 [==========================>...] - ETA: 0s - loss: 0.5870 - accuracy: 0.7997INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 103us/sample - loss: 0.5858 - accuracy: 0.7998 - val_loss: 0.5747 - val_accuracy: 0.7984\n",
      "Epoch 24/150\n",
      "10672/10672 [==============================] - ETA: 0s - loss: 0.5790 - accuracy: 0.8046INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 144us/sample - loss: 0.5790 - accuracy: 0.8046 - val_loss: 0.5681 - val_accuracy: 0.7999\n",
      "Epoch 25/150\n",
      " 9760/10672 [==========================>...] - ETA: 0s - loss: 0.5746 - accuracy: 0.8051INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 108us/sample - loss: 0.5726 - accuracy: 0.8068 - val_loss: 0.5618 - val_accuracy: 0.8028\n",
      "Epoch 26/150\n",
      " 9856/10672 [==========================>...] - ETA: 0s - loss: 0.5631 - accuracy: 0.8114INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 112us/sample - loss: 0.5665 - accuracy: 0.8098 - val_loss: 0.5559 - val_accuracy: 0.8066\n",
      "Epoch 27/150\n",
      " 9760/10672 [==========================>...] - ETA: 0s - loss: 0.5622 - accuracy: 0.8120INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 98us/sample - loss: 0.5606 - accuracy: 0.8130 - val_loss: 0.5501 - val_accuracy: 0.8096\n",
      "Epoch 28/150\n",
      " 9952/10672 [==========================>...] - ETA: 0s - loss: 0.5515 - accuracy: 0.8174INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 107us/sample - loss: 0.5551 - accuracy: 0.8158 - val_loss: 0.5447 - val_accuracy: 0.8156\n",
      "Epoch 29/150\n",
      "10368/10672 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.8183INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 171us/sample - loss: 0.5497 - accuracy: 0.8186 - val_loss: 0.5395 - val_accuracy: 0.8178\n",
      "Epoch 30/150\n",
      "10304/10672 [===========================>..] - ETA: 0s - loss: 0.5463 - accuracy: 0.8193INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 3s 236us/sample - loss: 0.5447 - accuracy: 0.8204 - val_loss: 0.5345 - val_accuracy: 0.8186\n",
      "Epoch 31/150\n",
      "10336/10672 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.8220INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 3s 255us/sample - loss: 0.5398 - accuracy: 0.8222 - val_loss: 0.5296 - val_accuracy: 0.8193\n",
      "Epoch 32/150\n",
      "10672/10672 [==============================] - 1s 100us/sample - loss: 0.5352 - accuracy: 0.8245 - val_loss: 0.5251 - val_accuracy: 0.8193\n",
      "Epoch 33/150\n",
      "10432/10672 [============================>.] - ETA: 0s - loss: 0.5308 - accuracy: 0.8258INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 163us/sample - loss: 0.5307 - accuracy: 0.8258 - val_loss: 0.5207 - val_accuracy: 0.8216\n",
      "Epoch 34/150\n",
      "10208/10672 [===========================>..] - ETA: 0s - loss: 0.5265 - accuracy: 0.8276INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 5s 462us/sample - loss: 0.5264 - accuracy: 0.8276 - val_loss: 0.5164 - val_accuracy: 0.8231\n",
      "Epoch 35/150\n",
      "10592/10672 [============================>.] - ETA: 0s - loss: 0.5229 - accuracy: 0.8291INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 185us/sample - loss: 0.5222 - accuracy: 0.8296 - val_loss: 0.5124 - val_accuracy: 0.8238\n",
      "Epoch 36/150\n",
      "10272/10672 [===========================>..] - ETA: 0s - loss: 0.5182 - accuracy: 0.8314INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 179us/sample - loss: 0.5183 - accuracy: 0.8311 - val_loss: 0.5085 - val_accuracy: 0.8253\n",
      "Epoch 37/150\n",
      "10208/10672 [===========================>..] - ETA: 0s - loss: 0.5142 - accuracy: 0.8329INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 150us/sample - loss: 0.5144 - accuracy: 0.8327 - val_loss: 0.5047 - val_accuracy: 0.8261\n",
      "Epoch 38/150\n",
      "10336/10672 [============================>.] - ETA: 0s - loss: 0.5112 - accuracy: 0.8337INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 154us/sample - loss: 0.5107 - accuracy: 0.8342 - val_loss: 0.5010 - val_accuracy: 0.8291\n",
      "Epoch 39/150\n",
      "10672/10672 [==============================] - 1s 76us/sample - loss: 0.5072 - accuracy: 0.8356 - val_loss: 0.4976 - val_accuracy: 0.8291\n",
      "Epoch 40/150\n",
      "10304/10672 [===========================>..] - ETA: 0s - loss: 0.5047 - accuracy: 0.8371INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 132us/sample - loss: 0.5037 - accuracy: 0.8378 - val_loss: 0.4942 - val_accuracy: 0.8306\n",
      "Epoch 41/150\n",
      "10496/10672 [============================>.] - ETA: 0s - loss: 0.4995 - accuracy: 0.8392INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 137us/sample - loss: 0.5004 - accuracy: 0.8389 - val_loss: 0.4909 - val_accuracy: 0.8328\n",
      "Epoch 42/150\n",
      "10672/10672 [==============================] - 1s 92us/sample - loss: 0.4972 - accuracy: 0.8402 - val_loss: 0.4878 - val_accuracy: 0.8328\n",
      "Epoch 43/150\n",
      "10432/10672 [============================>.] - ETA: 0s - loss: 0.4935 - accuracy: 0.8417INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 124us/sample - loss: 0.4941 - accuracy: 0.8410 - val_loss: 0.4847 - val_accuracy: 0.8351\n",
      "Epoch 44/150\n",
      "10592/10672 [============================>.] - ETA: 0s - loss: 0.4907 - accuracy: 0.8436INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 138us/sample - loss: 0.4911 - accuracy: 0.8432 - val_loss: 0.4818 - val_accuracy: 0.8373\n",
      "Epoch 45/150\n",
      "10672/10672 [==============================] - 1s 69us/sample - loss: 0.4882 - accuracy: 0.8441 - val_loss: 0.4789 - val_accuracy: 0.8373\n",
      "Epoch 46/150\n",
      "10432/10672 [============================>.] - ETA: 0s - loss: 0.4856 - accuracy: 0.8451INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 174us/sample - loss: 0.4854 - accuracy: 0.8454 - val_loss: 0.4761 - val_accuracy: 0.8388\n",
      "Epoch 47/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.4818 - accuracy: 0.8468INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 81us/sample - loss: 0.4827 - accuracy: 0.8464 - val_loss: 0.4734 - val_accuracy: 0.8396\n",
      "Epoch 48/150\n",
      "10528/10672 [============================>.] - ETA: 28s - loss: 0.4805 - accuracy: 0.8469 INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2063s 193ms/sample - loss: 0.4800 - accuracy: 0.8468 - val_loss: 0.4708 - val_accuracy: 0.8426\n",
      "Epoch 49/150\n",
      "10672/10672 [==============================] - 2s 165us/sample - loss: 0.4774 - accuracy: 0.8483 - val_loss: 0.4683 - val_accuracy: 0.8426\n",
      "Epoch 50/150\n",
      "10672/10672 [==============================] - 1s 118us/sample - loss: 0.4750 - accuracy: 0.8490 - val_loss: 0.4658 - val_accuracy: 0.8426\n",
      "Epoch 51/150\n",
      "10672/10672 [==============================] - 1s 99us/sample - loss: 0.4725 - accuracy: 0.8499 - val_loss: 0.4635 - val_accuracy: 0.8426\n",
      "Epoch 52/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.8510INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 173us/sample - loss: 0.4702 - accuracy: 0.8510 - val_loss: 0.4611 - val_accuracy: 0.8433\n",
      "Epoch 53/150\n",
      "10672/10672 [==============================] - 1s 82us/sample - loss: 0.4679 - accuracy: 0.8517 - val_loss: 0.4589 - val_accuracy: 0.8426\n",
      "Epoch 54/150\n",
      "10672/10672 [==============================] - 1s 82us/sample - loss: 0.4657 - accuracy: 0.8517 - val_loss: 0.4566 - val_accuracy: 0.8433\n",
      "Epoch 55/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8525INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 147us/sample - loss: 0.4635 - accuracy: 0.8529 - val_loss: 0.4545 - val_accuracy: 0.8448\n",
      "Epoch 56/150\n",
      "10592/10672 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8536INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 11s 1ms/sample - loss: 0.4614 - accuracy: 0.8534 - val_loss: 0.4524 - val_accuracy: 0.8471\n",
      "Epoch 57/150\n",
      "10656/10672 [============================>.] - ETA: 0s - loss: 0.4594 - accuracy: 0.8541INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 8s 712us/sample - loss: 0.4593 - accuracy: 0.8541 - val_loss: 0.4504 - val_accuracy: 0.8478\n",
      "Epoch 58/150\n",
      "10336/10672 [============================>.] - ETA: 0s - loss: 0.4572 - accuracy: 0.8547INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 5s 473us/sample - loss: 0.4573 - accuracy: 0.8549 - val_loss: 0.4485 - val_accuracy: 0.8486\n",
      "Epoch 59/150\n",
      " 9888/10672 [==========================>...] - ETA: 1s - loss: 0.4523 - accuracy: 0.8566INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 19s 2ms/sample - loss: 0.4554 - accuracy: 0.8553 - val_loss: 0.4465 - val_accuracy: 0.8508\n",
      "Epoch 60/150\n",
      "10672/10672 [==============================] - 1s 59us/sample - loss: 0.4535 - accuracy: 0.8559 - val_loss: 0.4447 - val_accuracy: 0.8508\n",
      "Epoch 61/150\n",
      " 9760/10672 [==========================>...] - ETA: 0s - loss: 0.4504 - accuracy: 0.8567INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 172us/sample - loss: 0.4516 - accuracy: 0.8561 - val_loss: 0.4428 - val_accuracy: 0.8516\n",
      "Epoch 62/150\n",
      "10432/10672 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8563INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 91us/sample - loss: 0.4498 - accuracy: 0.8569 - val_loss: 0.4411 - val_accuracy: 0.8523\n",
      "Epoch 63/150\n",
      "10672/10672 [==============================] - 0s 43us/sample - loss: 0.4480 - accuracy: 0.8581 - val_loss: 0.4393 - val_accuracy: 0.8523\n",
      "Epoch 64/150\n",
      "10672/10672 [==============================] - 0s 33us/sample - loss: 0.4463 - accuracy: 0.8583 - val_loss: 0.4376 - val_accuracy: 0.8516\n",
      "Epoch 65/150\n",
      "10672/10672 [==============================] - 0s 38us/sample - loss: 0.4446 - accuracy: 0.8593 - val_loss: 0.4360 - val_accuracy: 0.8523\n",
      "Epoch 66/150\n",
      "10672/10672 [==============================] - 1s 81us/sample - loss: 0.4430 - accuracy: 0.8599 - val_loss: 0.4344 - val_accuracy: 0.8523\n",
      "Epoch 67/150\n",
      " 9920/10672 [==========================>...] - ETA: 0s - loss: 0.4395 - accuracy: 0.8608INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 69us/sample - loss: 0.4413 - accuracy: 0.8602 - val_loss: 0.4328 - val_accuracy: 0.8538\n",
      "Epoch 68/150\n",
      " 9888/10672 [==========================>...] - ETA: 0s - loss: 0.4422 - accuracy: 0.8589INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 71us/sample - loss: 0.4398 - accuracy: 0.8604 - val_loss: 0.4312 - val_accuracy: 0.8553\n",
      "Epoch 69/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.4388 - accuracy: 0.8608INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 133us/sample - loss: 0.4382 - accuracy: 0.8609 - val_loss: 0.4297 - val_accuracy: 0.8561\n",
      "Epoch 70/150\n",
      "10672/10672 [==============================] - 0s 38us/sample - loss: 0.4367 - accuracy: 0.8613 - val_loss: 0.4283 - val_accuracy: 0.8561\n",
      "Epoch 71/150\n",
      " 9280/10672 [=========================>....] - ETA: 0s - loss: 0.4310 - accuracy: 0.8642INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 70us/sample - loss: 0.4353 - accuracy: 0.8621 - val_loss: 0.4268 - val_accuracy: 0.8568\n",
      "Epoch 72/150\n",
      "10672/10672 [==============================] - 7s 643us/sample - loss: 0.4338 - accuracy: 0.8628 - val_loss: 0.4254 - val_accuracy: 0.8568\n",
      "Epoch 73/150\n",
      "10432/10672 [============================>.] - ETA: 0s - loss: 0.4322 - accuracy: 0.8635INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 30s 3ms/sample - loss: 0.4324 - accuracy: 0.8631 - val_loss: 0.4240 - val_accuracy: 0.8576\n",
      "Epoch 74/150\n",
      "10656/10672 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8633INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 5s 472us/sample - loss: 0.4310 - accuracy: 0.8633 - val_loss: 0.4227 - val_accuracy: 0.8591\n",
      "Epoch 75/150\n",
      " 9600/10672 [=========================>....] - ETA: 9:22 - loss: 0.4300 - accuracy: 0.8641  INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 5034s 472ms/sample - loss: 0.4296 - accuracy: 0.8638 - val_loss: 0.4214 - val_accuracy: 0.8606\n",
      "Epoch 76/150\n",
      "10672/10672 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.8640INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 146us/sample - loss: 0.4283 - accuracy: 0.8640 - val_loss: 0.4201 - val_accuracy: 0.8613\n",
      "Epoch 77/150\n",
      " 9600/10672 [=========================>....] - ETA: 0s - loss: 0.4266 - accuracy: 0.8642INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 71us/sample - loss: 0.4270 - accuracy: 0.8638 - val_loss: 0.4188 - val_accuracy: 0.8621\n",
      "Epoch 78/150\n",
      " 9056/10672 [========================>.....] - ETA: 0s - loss: 0.4279 - accuracy: 0.8640INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 81us/sample - loss: 0.4257 - accuracy: 0.8650 - val_loss: 0.4175 - val_accuracy: 0.8628\n",
      "Epoch 79/150\n",
      "10672/10672 [==============================] - 0s 38us/sample - loss: 0.4245 - accuracy: 0.8646 - val_loss: 0.4163 - val_accuracy: 0.8628\n",
      "Epoch 80/150\n",
      "10560/10672 [============================>.] - ETA: 14s - loss: 0.4236 - accuracy: 0.8652INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1332s 125ms/sample - loss: 0.4233 - accuracy: 0.8653 - val_loss: 0.4151 - val_accuracy: 0.8636\n",
      "Epoch 81/150\n",
      "10672/10672 [==============================] - 1s 55us/sample - loss: 0.4221 - accuracy: 0.8654 - val_loss: 0.4139 - val_accuracy: 0.8636\n",
      "Epoch 82/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.4209 - accuracy: 0.8658INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 97us/sample - loss: 0.4209 - accuracy: 0.8662 - val_loss: 0.4128 - val_accuracy: 0.8643\n",
      "Epoch 83/150\n",
      "10656/10672 [============================>.] - ETA: 0s - loss: 0.4197 - accuracy: 0.8661INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 72us/sample - loss: 0.4197 - accuracy: 0.8661 - val_loss: 0.4116 - val_accuracy: 0.8651\n",
      "Epoch 84/150\n",
      "10672/10672 [==============================] - 1s 72us/sample - loss: 0.4186 - accuracy: 0.8668 - val_loss: 0.4105 - val_accuracy: 0.8651\n",
      "Epoch 85/150\n",
      "10672/10672 [==============================] - 1s 61us/sample - loss: 0.4175 - accuracy: 0.8673 - val_loss: 0.4094 - val_accuracy: 0.8651\n",
      "Epoch 86/150\n",
      "10176/10672 [===========================>..] - ETA: 0s - loss: 0.4167 - accuracy: 0.8665INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 82us/sample - loss: 0.4164 - accuracy: 0.8669 - val_loss: 0.4084 - val_accuracy: 0.8666\n",
      "Epoch 87/150\n",
      " 9056/10672 [========================>.....] - ETA: 0s - loss: 0.4129 - accuracy: 0.8669INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 80us/sample - loss: 0.4153 - accuracy: 0.8673 - val_loss: 0.4073 - val_accuracy: 0.8673\n",
      "Epoch 88/150\n",
      "10672/10672 [==============================] - 1s 106us/sample - loss: 0.4142 - accuracy: 0.8677 - val_loss: 0.4063 - val_accuracy: 0.8673\n",
      "Epoch 89/150\n",
      "10176/10672 [===========================>..] - ETA: 0s - loss: 0.4147 - accuracy: 0.8666 ETA: 0s - loss: 0.412INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 2s 152us/sample - loss: 0.4132 - accuracy: 0.8677 - val_loss: 0.4053 - val_accuracy: 0.8688\n",
      "Epoch 90/150\n",
      "10672/10672 [==============================] - 1s 60us/sample - loss: 0.4122 - accuracy: 0.8682 - val_loss: 0.4043 - val_accuracy: 0.8688\n",
      "Epoch 91/150\n",
      "10672/10672 [==============================] - 1s 68us/sample - loss: 0.4111 - accuracy: 0.8680 - val_loss: 0.4033 - val_accuracy: 0.8688\n",
      "Epoch 92/150\n",
      "10672/10672 [==============================] - 1s 65us/sample - loss: 0.4102 - accuracy: 0.8683 - val_loss: 0.4024 - val_accuracy: 0.8688\n",
      "Epoch 93/150\n",
      "10672/10672 [==============================] - 1s 63us/sample - loss: 0.4092 - accuracy: 0.8686 - val_loss: 0.4014 - val_accuracy: 0.8688\n",
      "Epoch 94/150\n",
      "10672/10672 [==============================] - 1s 63us/sample - loss: 0.4082 - accuracy: 0.8693 - val_loss: 0.4005 - val_accuracy: 0.8673\n",
      "Epoch 95/150\n",
      "10672/10672 [==============================] - 1s 54us/sample - loss: 0.4073 - accuracy: 0.8687 - val_loss: 0.3996 - val_accuracy: 0.8673\n",
      "Epoch 96/150\n",
      "10672/10672 [==============================] - 1s 54us/sample - loss: 0.4064 - accuracy: 0.8691 - val_loss: 0.3987 - val_accuracy: 0.8681\n",
      "Epoch 97/150\n",
      "10672/10672 [==============================] - 1s 65us/sample - loss: 0.4054 - accuracy: 0.8694 - val_loss: 0.3978 - val_accuracy: 0.8688\n",
      "Epoch 98/150\n",
      "10672/10672 [==============================] - 0s 40us/sample - loss: 0.4046 - accuracy: 0.8697 - val_loss: 0.3969 - val_accuracy: 0.8688\n",
      "Epoch 99/150\n",
      "10112/10672 [===========================>..] - ETA: 0s - loss: 0.4044 - accuracy: 0.8702INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 87us/sample - loss: 0.4037 - accuracy: 0.8706 - val_loss: 0.3961 - val_accuracy: 0.8703\n",
      "Epoch 100/150\n",
      " 9568/10672 [=========================>....] - ETA: 0s - loss: 0.4019 - accuracy: 0.8700INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 96us/sample - loss: 0.4028 - accuracy: 0.8701 - val_loss: 0.3952 - val_accuracy: 0.8711\n",
      "Epoch 101/150\n",
      "10672/10672 [==============================] - 0s 40us/sample - loss: 0.4019 - accuracy: 0.8705 - val_loss: 0.3944 - val_accuracy: 0.8711\n",
      "Epoch 102/150\n",
      " 9440/10672 [=========================>....] - ETA: 0s - loss: 0.4027 - accuracy: 0.8700INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 84us/sample - loss: 0.4011 - accuracy: 0.8705 - val_loss: 0.3936 - val_accuracy: 0.8733\n",
      "Epoch 103/150\n",
      "10672/10672 [==============================] - 0s 41us/sample - loss: 0.4003 - accuracy: 0.8712 - val_loss: 0.3927 - val_accuracy: 0.8733\n",
      "Epoch 104/150\n",
      "10528/10672 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.8717INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 88us/sample - loss: 0.3994 - accuracy: 0.8718 - val_loss: 0.3920 - val_accuracy: 0.8741\n",
      "Epoch 105/150\n",
      "10672/10672 [==============================] - 0s 44us/sample - loss: 0.3986 - accuracy: 0.8717 - val_loss: 0.3912 - val_accuracy: 0.8733\n",
      "Epoch 106/150\n",
      "10672/10672 [==============================] - 0s 35us/sample - loss: 0.3978 - accuracy: 0.8719 - val_loss: 0.3904 - val_accuracy: 0.8733\n",
      "Epoch 107/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3970 - accuracy: 0.8720 - val_loss: 0.3897 - val_accuracy: 0.8733\n",
      "Epoch 108/150\n",
      "10672/10672 [==============================] - 1s 52us/sample - loss: 0.3963 - accuracy: 0.8721 - val_loss: 0.3889 - val_accuracy: 0.8733\n",
      "Epoch 109/150\n",
      " 9408/10672 [=========================>....] - ETA: 0s - loss: 0.3991 - accuracy: 0.8700INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 73us/sample - loss: 0.3955 - accuracy: 0.8719 - val_loss: 0.3882 - val_accuracy: 0.8748\n",
      "Epoch 110/150\n",
      " 9792/10672 [==========================>...] - ETA: 0s - loss: 0.3934 - accuracy: 0.8723INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 92us/sample - loss: 0.3947 - accuracy: 0.8721 - val_loss: 0.3875 - val_accuracy: 0.8756\n",
      "Epoch 111/150\n",
      "10672/10672 [==============================] - 0s 43us/sample - loss: 0.3940 - accuracy: 0.8725 - val_loss: 0.3868 - val_accuracy: 0.8756\n",
      "Epoch 112/150\n",
      "10672/10672 [==============================] - 0s 34us/sample - loss: 0.3933 - accuracy: 0.8725 - val_loss: 0.3861 - val_accuracy: 0.8756\n",
      "Epoch 113/150\n",
      "10672/10672 [==============================] - 0s 28us/sample - loss: 0.3926 - accuracy: 0.8721 - val_loss: 0.3854 - val_accuracy: 0.8756\n",
      "Epoch 114/150\n",
      "10672/10672 [==============================] - 0s 32us/sample - loss: 0.3919 - accuracy: 0.8728 - val_loss: 0.3847 - val_accuracy: 0.8756\n",
      "Epoch 115/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3912 - accuracy: 0.8728 - val_loss: 0.3840 - val_accuracy: 0.8756\n",
      "Epoch 116/150\n",
      "10672/10672 [==============================] - 0s 39us/sample - loss: 0.3905 - accuracy: 0.8729 - val_loss: 0.3834 - val_accuracy: 0.8756\n",
      "Epoch 117/150\n",
      "10672/10672 [==============================] - 0s 40us/sample - loss: 0.3898 - accuracy: 0.8730 - val_loss: 0.3827 - val_accuracy: 0.8756\n",
      "Epoch 118/150\n",
      " 9504/10672 [=========================>....] - ETA: 0s - loss: 0.3904 - accuracy: 0.8719INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 67us/sample - loss: 0.3891 - accuracy: 0.8730 - val_loss: 0.3821 - val_accuracy: 0.8763\n",
      "Epoch 119/150\n",
      "10672/10672 [==============================] - 0s 33us/sample - loss: 0.3884 - accuracy: 0.8735 - val_loss: 0.3814 - val_accuracy: 0.8763\n",
      "Epoch 120/150\n",
      "10112/10672 [===========================>..] - ETA: 0s - loss: 0.3877 - accuracy: 0.8733INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 87us/sample - loss: 0.3878 - accuracy: 0.8733 - val_loss: 0.3808 - val_accuracy: 0.8771\n",
      "Epoch 121/150\n",
      "10672/10672 [==============================] - 1s 51us/sample - loss: 0.3871 - accuracy: 0.8735 - val_loss: 0.3802 - val_accuracy: 0.8771\n",
      "Epoch 122/150\n",
      " 9344/10672 [=========================>....] - ETA: 0s - loss: 0.3877 - accuracy: 0.8731INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 77us/sample - loss: 0.3865 - accuracy: 0.8738 - val_loss: 0.3796 - val_accuracy: 0.8778\n",
      "Epoch 123/150\n",
      "10672/10672 [==============================] - 0s 44us/sample - loss: 0.3859 - accuracy: 0.8741 - val_loss: 0.3790 - val_accuracy: 0.8778\n",
      "Epoch 124/150\n",
      "10672/10672 [==============================] - 0s 42us/sample - loss: 0.3852 - accuracy: 0.8741 - val_loss: 0.3784 - val_accuracy: 0.8778\n",
      "Epoch 125/150\n",
      " 9088/10672 [========================>.....] - ETA: 0s - loss: 0.3847 - accuracy: 0.8758INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 68us/sample - loss: 0.3846 - accuracy: 0.8741 - val_loss: 0.3778 - val_accuracy: 0.8786\n",
      "Epoch 126/150\n",
      "10672/10672 [==============================] - 0s 34us/sample - loss: 0.3840 - accuracy: 0.8743 - val_loss: 0.3772 - val_accuracy: 0.8786\n",
      "Epoch 127/150\n",
      "10672/10672 [==============================] - 0s 31us/sample - loss: 0.3834 - accuracy: 0.8742 - val_loss: 0.3767 - val_accuracy: 0.8786\n",
      "Epoch 128/150\n",
      "10672/10672 [==============================] - 0s 33us/sample - loss: 0.3828 - accuracy: 0.8743 - val_loss: 0.3761 - val_accuracy: 0.8786\n",
      "Epoch 129/150\n",
      "10672/10672 [==============================] - 0s 47us/sample - loss: 0.3822 - accuracy: 0.8743 - val_loss: 0.3755 - val_accuracy: 0.8786\n",
      "Epoch 130/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3816 - accuracy: 0.8744 - val_loss: 0.3750 - val_accuracy: 0.8786\n",
      "Epoch 131/150\n",
      "10672/10672 [==============================] - 0s 29us/sample - loss: 0.3811 - accuracy: 0.8747 - val_loss: 0.3744 - val_accuracy: 0.8778\n",
      "Epoch 132/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3805 - accuracy: 0.8756 - val_loss: 0.3739 - val_accuracy: 0.8771\n",
      "Epoch 133/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3799 - accuracy: 0.8757 - val_loss: 0.3734 - val_accuracy: 0.8763\n",
      "Epoch 134/150\n",
      "10672/10672 [==============================] - 0s 38us/sample - loss: 0.3794 - accuracy: 0.8753 - val_loss: 0.3729 - val_accuracy: 0.8778\n",
      "Epoch 135/150\n",
      "10672/10672 [==============================] - 0s 45us/sample - loss: 0.3788 - accuracy: 0.8757 - val_loss: 0.3723 - val_accuracy: 0.8778\n",
      "Epoch 136/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3783 - accuracy: 0.8762 - val_loss: 0.3718 - val_accuracy: 0.8778\n",
      "Epoch 137/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3778 - accuracy: 0.8758 - val_loss: 0.3713 - val_accuracy: 0.8778\n",
      "Epoch 138/150\n",
      "10672/10672 [==============================] - 0s 40us/sample - loss: 0.3772 - accuracy: 0.8760 - val_loss: 0.3708 - val_accuracy: 0.8778\n",
      "Epoch 139/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3767 - accuracy: 0.8757 - val_loss: 0.3703 - val_accuracy: 0.8771\n",
      "Epoch 140/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3762 - accuracy: 0.8761 - val_loss: 0.3698 - val_accuracy: 0.8778\n",
      "Epoch 141/150\n",
      "10304/10672 [===========================>..] - ETA: 0s - loss: 0.3750 - accuracy: 0.8764INFO:tensorflow:Assets written to: checkpoint/assets\n",
      "10672/10672 [==============================] - 1s 82us/sample - loss: 0.3757 - accuracy: 0.8761 - val_loss: 0.3693 - val_accuracy: 0.8801\n",
      "Epoch 142/150\n",
      "10672/10672 [==============================] - 0s 33us/sample - loss: 0.3752 - accuracy: 0.8761 - val_loss: 0.3689 - val_accuracy: 0.8801\n",
      "Epoch 143/150\n",
      "10672/10672 [==============================] - 0s 33us/sample - loss: 0.3747 - accuracy: 0.8762 - val_loss: 0.3684 - val_accuracy: 0.8801\n",
      "Epoch 144/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3742 - accuracy: 0.8762 - val_loss: 0.3679 - val_accuracy: 0.8793\n",
      "Epoch 145/150\n",
      "10672/10672 [==============================] - 1s 57us/sample - loss: 0.3737 - accuracy: 0.8765 - val_loss: 0.3675 - val_accuracy: 0.8786\n",
      "Epoch 146/150\n",
      "10672/10672 [==============================] - 0s 33us/sample - loss: 0.3732 - accuracy: 0.8763 - val_loss: 0.3670 - val_accuracy: 0.8793\n",
      "Epoch 147/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3727 - accuracy: 0.8762 - val_loss: 0.3665 - val_accuracy: 0.8793\n",
      "Epoch 148/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3722 - accuracy: 0.8765 - val_loss: 0.3661 - val_accuracy: 0.8793\n",
      "Epoch 149/150\n",
      "10672/10672 [==============================] - 0s 30us/sample - loss: 0.3718 - accuracy: 0.8764 - val_loss: 0.3657 - val_accuracy: 0.8786\n",
      "Epoch 150/150\n",
      "10672/10672 [==============================] - 0s 34us/sample - loss: 0.3713 - accuracy: 0.8764 - val_loss: 0.3652 - val_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(train_X, train_Y, epochs=150, \\\n",
    "    validation_data=(test_X,test_Y), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "74. 正解率の計測  \n",
    "    問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuraccy : 0.87640554\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(train_X, train_Y)\n",
    "print('accuraccy :', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuraccy : 0.8785607\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(valid_X, valid_Y)\n",
    "print('accuraccy :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75. 損失と正解率のプロット  \n",
    "    問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his.history['loss'])\n",
    "plt.plot(his.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his.history['accuracy'])\n",
    "plt.plot(his.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77. ミニバッチ化  \n",
    "    問題76のコードを改変し，$B$事例ごとに損失・勾配を計算し，行列$W$の値を更新せよ（ミニバッチ化）．$B$の値を$1,2,4,8, \\dots$と変化させながら，1エポックの学習に要する時間を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size : 1\n",
      "10672/10672 [==============================] - 32s 3ms/step - loss: 0.4291 - accuracy: 0.8609 - val_loss: 0.4018 - val_accuracy: 0.8703\n",
      "Batch Size : 2\n",
      "5336/5336 [==============================] - 38s 7ms/step - loss: 0.4027 - accuracy: 0.8707 - val_loss: 0.3884 - val_accuracy: 0.8711\n",
      "Batch Size : 4\n",
      "2668/2668 [==============================] - 14s 5ms/step - loss: 0.3927 - accuracy: 0.8721 - val_loss: 0.3825 - val_accuracy: 0.8733\n",
      "Batch Size : 8\n",
      "1334/1334 [==============================] - 6s 5ms/step - loss: 0.3884 - accuracy: 0.8731 - val_loss: 0.3800 - val_accuracy: 0.8733\n",
      "Batch Size : 16\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.3863 - accuracy: 0.8743 - val_loss: 0.3789 - val_accuracy: 0.8726\n",
      "Batch Size : 32\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3853 - accuracy: 0.8742 - val_loss: 0.3783 - val_accuracy: 0.8726\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    n_batch = 2**i\n",
    "    print('Batch Size :', n_batch)\n",
    "    model.fit(train_X, train_Y, batch_size=n_batch, epochs=1, validation_data=(test_X,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "78. GPU上での学習  \n",
    "    問題77のコードを改変し，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "with tf.device('/CPU:0'):\n",
    "    his = model.fit(train_X, train_Y, epochs=150, \\\n",
    "        validation_data=(test_X,test_Y), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79. 多層ニューラルネットワーク\n",
    "    問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "334/334 [==============================] - 2s 4ms/step - loss: 1.1810 - accuracy: 0.4457 - val_loss: 1.1503 - val_accuracy: 0.4280\n",
      "Epoch 2/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 1.1436 - accuracy: 0.5522 - val_loss: 1.1355 - val_accuracy: 0.4565\n",
      "Epoch 3/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 1.1280 - accuracy: 0.6142 - val_loss: 1.1182 - val_accuracy: 0.7399\n",
      "Epoch 4/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 1.1101 - accuracy: 0.6765 - val_loss: 1.0993 - val_accuracy: 0.7406\n",
      "Epoch 5/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 1.0901 - accuracy: 0.7179 - val_loss: 1.0776 - val_accuracy: 0.7241\n",
      "Epoch 6/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 1.0667 - accuracy: 0.7312 - val_loss: 1.0526 - val_accuracy: 0.7294\n",
      "Epoch 7/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 1.0405 - accuracy: 0.7482 - val_loss: 1.0245 - val_accuracy: 0.7519\n",
      "Epoch 8/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 1.0114 - accuracy: 0.7538 - val_loss: 0.9942 - val_accuracy: 0.7571\n",
      "Epoch 9/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.9806 - accuracy: 0.7567 - val_loss: 0.9609 - val_accuracy: 0.7564\n",
      "Epoch 10/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.9481 - accuracy: 0.7596 - val_loss: 0.9278 - val_accuracy: 0.7631\n",
      "Epoch 11/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.9154 - accuracy: 0.7621 - val_loss: 0.8952 - val_accuracy: 0.7616\n",
      "Epoch 12/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.8839 - accuracy: 0.7609 - val_loss: 0.8643 - val_accuracy: 0.7639\n",
      "Epoch 13/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.8543 - accuracy: 0.7625 - val_loss: 0.8355 - val_accuracy: 0.7646\n",
      "Epoch 14/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.8271 - accuracy: 0.7641 - val_loss: 0.8099 - val_accuracy: 0.7631\n",
      "Epoch 15/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.8023 - accuracy: 0.7648 - val_loss: 0.7849 - val_accuracy: 0.7676\n",
      "Epoch 16/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.7801 - accuracy: 0.7657 - val_loss: 0.7643 - val_accuracy: 0.7646\n",
      "Epoch 17/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.7601 - accuracy: 0.7669 - val_loss: 0.7449 - val_accuracy: 0.7676\n",
      "Epoch 18/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.7425 - accuracy: 0.7671 - val_loss: 0.7276 - val_accuracy: 0.7684\n",
      "Epoch 19/150\n",
      "334/334 [==============================] - 2s 4ms/step - loss: 0.7264 - accuracy: 0.7686 - val_loss: 0.7128 - val_accuracy: 0.7684\n",
      "Epoch 20/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.7122 - accuracy: 0.7683 - val_loss: 0.6992 - val_accuracy: 0.7691\n",
      "Epoch 21/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6996 - accuracy: 0.7701 - val_loss: 0.6862 - val_accuracy: 0.7706\n",
      "Epoch 22/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.6878 - accuracy: 0.7703 - val_loss: 0.6767 - val_accuracy: 0.7714\n",
      "Epoch 23/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6774 - accuracy: 0.7716 - val_loss: 0.6654 - val_accuracy: 0.7691\n",
      "Epoch 24/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7716 - val_loss: 0.6550 - val_accuracy: 0.7736\n",
      "Epoch 25/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6590 - accuracy: 0.7729 - val_loss: 0.6460 - val_accuracy: 0.7766\n",
      "Epoch 26/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6508 - accuracy: 0.7732 - val_loss: 0.6380 - val_accuracy: 0.7759\n",
      "Epoch 27/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6432 - accuracy: 0.7744 - val_loss: 0.6306 - val_accuracy: 0.7751\n",
      "Epoch 28/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6357 - accuracy: 0.7736 - val_loss: 0.6236 - val_accuracy: 0.7774\n",
      "Epoch 29/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.7751 - val_loss: 0.6169 - val_accuracy: 0.7781\n",
      "Epoch 30/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6227 - accuracy: 0.7767 - val_loss: 0.6105 - val_accuracy: 0.7766\n",
      "Epoch 31/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6167 - accuracy: 0.7768 - val_loss: 0.6035 - val_accuracy: 0.7789\n",
      "Epoch 32/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.6107 - accuracy: 0.7771 - val_loss: 0.5978 - val_accuracy: 0.7789\n",
      "Epoch 33/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.6050 - accuracy: 0.7768 - val_loss: 0.5921 - val_accuracy: 0.7789\n",
      "Epoch 34/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.5998 - accuracy: 0.7777 - val_loss: 0.5875 - val_accuracy: 0.7774\n",
      "Epoch 35/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5944 - accuracy: 0.7777 - val_loss: 0.5817 - val_accuracy: 0.7789\n",
      "Epoch 36/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5894 - accuracy: 0.7793 - val_loss: 0.5768 - val_accuracy: 0.7789\n",
      "Epoch 37/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.7803 - val_loss: 0.5720 - val_accuracy: 0.7841\n",
      "Epoch 38/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5794 - accuracy: 0.7813 - val_loss: 0.5670 - val_accuracy: 0.7819\n",
      "Epoch 39/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5752 - accuracy: 0.7821 - val_loss: 0.5616 - val_accuracy: 0.7856\n",
      "Epoch 40/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5704 - accuracy: 0.7845 - val_loss: 0.5572 - val_accuracy: 0.7856\n",
      "Epoch 41/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.7872 - val_loss: 0.5526 - val_accuracy: 0.7856\n",
      "Epoch 42/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5615 - accuracy: 0.7873 - val_loss: 0.5476 - val_accuracy: 0.7879\n",
      "Epoch 43/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5570 - accuracy: 0.7904 - val_loss: 0.5434 - val_accuracy: 0.7879\n",
      "Epoch 44/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5526 - accuracy: 0.7910 - val_loss: 0.5395 - val_accuracy: 0.7916\n",
      "Epoch 45/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5484 - accuracy: 0.7955 - val_loss: 0.5351 - val_accuracy: 0.7909\n",
      "Epoch 46/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5441 - accuracy: 0.7976 - val_loss: 0.5303 - val_accuracy: 0.7984\n",
      "Epoch 47/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5398 - accuracy: 0.8008 - val_loss: 0.5268 - val_accuracy: 0.7939\n",
      "Epoch 48/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5356 - accuracy: 0.8019 - val_loss: 0.5220 - val_accuracy: 0.7991\n",
      "Epoch 49/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5314 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.8058\n",
      "Epoch 50/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5274 - accuracy: 0.8071 - val_loss: 0.5135 - val_accuracy: 0.8103\n",
      "Epoch 51/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5234 - accuracy: 0.8105 - val_loss: 0.5101 - val_accuracy: 0.8066\n",
      "Epoch 52/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5195 - accuracy: 0.8115 - val_loss: 0.5062 - val_accuracy: 0.8088\n",
      "Epoch 53/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5156 - accuracy: 0.8138 - val_loss: 0.5018 - val_accuracy: 0.8126\n",
      "Epoch 54/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5115 - accuracy: 0.8170 - val_loss: 0.4976 - val_accuracy: 0.8156\n",
      "Epoch 55/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5071 - accuracy: 0.8203 - val_loss: 0.4957 - val_accuracy: 0.8133\n",
      "Epoch 56/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.5038 - accuracy: 0.8215 - val_loss: 0.4900 - val_accuracy: 0.8186\n",
      "Epoch 57/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4998 - accuracy: 0.8237 - val_loss: 0.4859 - val_accuracy: 0.8216\n",
      "Epoch 58/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4960 - accuracy: 0.8264 - val_loss: 0.4829 - val_accuracy: 0.8193\n",
      "Epoch 59/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4921 - accuracy: 0.8291 - val_loss: 0.4793 - val_accuracy: 0.8231\n",
      "Epoch 60/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4886 - accuracy: 0.8296 - val_loss: 0.4756 - val_accuracy: 0.8253\n",
      "Epoch 61/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.4848 - accuracy: 0.8323 - val_loss: 0.4714 - val_accuracy: 0.8253\n",
      "Epoch 62/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4812 - accuracy: 0.8329 - val_loss: 0.4680 - val_accuracy: 0.8306\n",
      "Epoch 63/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.4776 - accuracy: 0.8352 - val_loss: 0.4640 - val_accuracy: 0.8358\n",
      "Epoch 64/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4742 - accuracy: 0.8388 - val_loss: 0.4608 - val_accuracy: 0.8313\n",
      "Epoch 65/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4706 - accuracy: 0.8400 - val_loss: 0.4580 - val_accuracy: 0.8291\n",
      "Epoch 66/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4671 - accuracy: 0.8403 - val_loss: 0.4538 - val_accuracy: 0.8373\n",
      "Epoch 67/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4639 - accuracy: 0.8427 - val_loss: 0.4508 - val_accuracy: 0.8411\n",
      "Epoch 68/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4605 - accuracy: 0.8436 - val_loss: 0.4475 - val_accuracy: 0.8373\n",
      "Epoch 69/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4572 - accuracy: 0.8452 - val_loss: 0.4447 - val_accuracy: 0.8433\n",
      "Epoch 70/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.8462 - val_loss: 0.4415 - val_accuracy: 0.8388\n",
      "Epoch 71/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4509 - accuracy: 0.8471 - val_loss: 0.4377 - val_accuracy: 0.8486\n",
      "Epoch 72/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4476 - accuracy: 0.8487 - val_loss: 0.4353 - val_accuracy: 0.8471\n",
      "Epoch 73/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4447 - accuracy: 0.8503 - val_loss: 0.4323 - val_accuracy: 0.8508\n",
      "Epoch 74/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4417 - accuracy: 0.8519 - val_loss: 0.4288 - val_accuracy: 0.8531\n",
      "Epoch 75/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4386 - accuracy: 0.8533 - val_loss: 0.4264 - val_accuracy: 0.8516\n",
      "Epoch 76/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4358 - accuracy: 0.8549 - val_loss: 0.4235 - val_accuracy: 0.8531\n",
      "Epoch 77/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4330 - accuracy: 0.8554 - val_loss: 0.4209 - val_accuracy: 0.8516\n",
      "Epoch 78/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4302 - accuracy: 0.8562 - val_loss: 0.4184 - val_accuracy: 0.8516\n",
      "Epoch 79/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4274 - accuracy: 0.8567 - val_loss: 0.4157 - val_accuracy: 0.8508\n",
      "Epoch 80/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.8577 - val_loss: 0.4130 - val_accuracy: 0.8531\n",
      "Epoch 81/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.8586 - val_loss: 0.4104 - val_accuracy: 0.8531\n",
      "Epoch 82/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4195 - accuracy: 0.8598 - val_loss: 0.4078 - val_accuracy: 0.8598\n",
      "Epoch 83/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4171 - accuracy: 0.8603 - val_loss: 0.4056 - val_accuracy: 0.8591\n",
      "Epoch 84/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4146 - accuracy: 0.8622 - val_loss: 0.4032 - val_accuracy: 0.8561\n",
      "Epoch 85/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.4123 - accuracy: 0.8624 - val_loss: 0.4015 - val_accuracy: 0.8598\n",
      "Epoch 86/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4099 - accuracy: 0.8624 - val_loss: 0.3986 - val_accuracy: 0.8621\n",
      "Epoch 87/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.8645 - val_loss: 0.3962 - val_accuracy: 0.8613\n",
      "Epoch 88/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4053 - accuracy: 0.8654 - val_loss: 0.3946 - val_accuracy: 0.8651\n",
      "Epoch 89/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4032 - accuracy: 0.8659 - val_loss: 0.3924 - val_accuracy: 0.8606\n",
      "Epoch 90/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.4011 - accuracy: 0.8662 - val_loss: 0.3901 - val_accuracy: 0.8606\n",
      "Epoch 91/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3990 - accuracy: 0.8675 - val_loss: 0.3883 - val_accuracy: 0.8598\n",
      "Epoch 92/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8683 - val_loss: 0.3864 - val_accuracy: 0.8643\n",
      "Epoch 93/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3950 - accuracy: 0.8689 - val_loss: 0.3848 - val_accuracy: 0.8613\n",
      "Epoch 94/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3929 - accuracy: 0.8701 - val_loss: 0.3830 - val_accuracy: 0.8666\n",
      "Epoch 95/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3911 - accuracy: 0.8708 - val_loss: 0.3811 - val_accuracy: 0.8696\n",
      "Epoch 96/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3893 - accuracy: 0.8705 - val_loss: 0.3794 - val_accuracy: 0.8718\n",
      "Epoch 97/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3872 - accuracy: 0.8727 - val_loss: 0.3775 - val_accuracy: 0.8703\n",
      "Epoch 98/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3856 - accuracy: 0.8701 - val_loss: 0.3755 - val_accuracy: 0.8733\n",
      "Epoch 99/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3837 - accuracy: 0.8730 - val_loss: 0.3740 - val_accuracy: 0.8726\n",
      "Epoch 100/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3822 - accuracy: 0.8713 - val_loss: 0.3724 - val_accuracy: 0.8741\n",
      "Epoch 101/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3805 - accuracy: 0.8735 - val_loss: 0.3713 - val_accuracy: 0.8718\n",
      "Epoch 102/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.8742 - val_loss: 0.3696 - val_accuracy: 0.8733\n",
      "Epoch 103/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8742 - val_loss: 0.3683 - val_accuracy: 0.8778\n",
      "Epoch 104/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3759 - accuracy: 0.8741 - val_loss: 0.3667 - val_accuracy: 0.8778\n",
      "Epoch 105/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8756 - val_loss: 0.3660 - val_accuracy: 0.8726\n",
      "Epoch 106/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3728 - accuracy: 0.8745 - val_loss: 0.3642 - val_accuracy: 0.8771\n",
      "Epoch 107/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3715 - accuracy: 0.8758 - val_loss: 0.3629 - val_accuracy: 0.8756\n",
      "Epoch 108/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3699 - accuracy: 0.8757 - val_loss: 0.3617 - val_accuracy: 0.8793\n",
      "Epoch 109/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3684 - accuracy: 0.8757 - val_loss: 0.3598 - val_accuracy: 0.8808\n",
      "Epoch 110/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3673 - accuracy: 0.8770 - val_loss: 0.3592 - val_accuracy: 0.8778\n",
      "Epoch 111/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3660 - accuracy: 0.8771 - val_loss: 0.3578 - val_accuracy: 0.8771\n",
      "Epoch 112/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3647 - accuracy: 0.8772 - val_loss: 0.3565 - val_accuracy: 0.8801\n",
      "Epoch 113/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3634 - accuracy: 0.8782 - val_loss: 0.3554 - val_accuracy: 0.8801\n",
      "Epoch 114/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8774 - val_loss: 0.3542 - val_accuracy: 0.8801\n",
      "Epoch 115/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3609 - accuracy: 0.8779 - val_loss: 0.3533 - val_accuracy: 0.8786\n",
      "Epoch 116/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8788 - val_loss: 0.3522 - val_accuracy: 0.8786\n",
      "Epoch 117/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.8785 - val_loss: 0.3513 - val_accuracy: 0.8786\n",
      "Epoch 118/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.8785 - val_loss: 0.3504 - val_accuracy: 0.8786\n",
      "Epoch 119/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3565 - accuracy: 0.8784 - val_loss: 0.3496 - val_accuracy: 0.8831\n",
      "Epoch 120/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.8778 - val_loss: 0.3487 - val_accuracy: 0.8831\n",
      "Epoch 121/150\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8776 - val_loss: 0.3474 - val_accuracy: 0.8816\n",
      "Epoch 122/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3533 - accuracy: 0.8794 - val_loss: 0.3467 - val_accuracy: 0.8838\n",
      "Epoch 123/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3521 - accuracy: 0.8791 - val_loss: 0.3463 - val_accuracy: 0.8793\n",
      "Epoch 124/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8812 - val_loss: 0.3447 - val_accuracy: 0.8808\n",
      "Epoch 125/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8797 - val_loss: 0.3440 - val_accuracy: 0.8808\n",
      "Epoch 126/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3494 - accuracy: 0.8800 - val_loss: 0.3434 - val_accuracy: 0.8808\n",
      "Epoch 127/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3485 - accuracy: 0.8815 - val_loss: 0.3421 - val_accuracy: 0.8823\n",
      "Epoch 128/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3475 - accuracy: 0.8814 - val_loss: 0.3411 - val_accuracy: 0.8816\n",
      "Epoch 129/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3466 - accuracy: 0.8817 - val_loss: 0.3403 - val_accuracy: 0.8823\n",
      "Epoch 130/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3457 - accuracy: 0.8818 - val_loss: 0.3403 - val_accuracy: 0.8816\n",
      "Epoch 131/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3448 - accuracy: 0.8817 - val_loss: 0.3390 - val_accuracy: 0.8853\n",
      "Epoch 132/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.8834 - val_loss: 0.3389 - val_accuracy: 0.8816\n",
      "Epoch 133/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3432 - accuracy: 0.8832 - val_loss: 0.3376 - val_accuracy: 0.8823\n",
      "Epoch 134/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8833 - val_loss: 0.3364 - val_accuracy: 0.8846\n",
      "Epoch 135/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.8834 - val_loss: 0.3358 - val_accuracy: 0.8861\n",
      "Epoch 136/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3407 - accuracy: 0.8836 - val_loss: 0.3353 - val_accuracy: 0.8823\n",
      "Epoch 137/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3400 - accuracy: 0.8847 - val_loss: 0.3350 - val_accuracy: 0.8823\n",
      "Epoch 138/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3391 - accuracy: 0.8841 - val_loss: 0.3344 - val_accuracy: 0.8823\n",
      "Epoch 139/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3382 - accuracy: 0.8842 - val_loss: 0.3331 - val_accuracy: 0.8853\n",
      "Epoch 140/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3377 - accuracy: 0.8845 - val_loss: 0.3328 - val_accuracy: 0.8876\n",
      "Epoch 141/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3371 - accuracy: 0.8845 - val_loss: 0.3326 - val_accuracy: 0.8823\n",
      "Epoch 142/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8846 - val_loss: 0.3317 - val_accuracy: 0.8853\n",
      "Epoch 143/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8852 - val_loss: 0.3308 - val_accuracy: 0.8861\n",
      "Epoch 144/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.8852 - val_loss: 0.3301 - val_accuracy: 0.8853\n",
      "Epoch 145/150\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3341 - accuracy: 0.8861 - val_loss: 0.3302 - val_accuracy: 0.8823\n",
      "Epoch 146/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8854 - val_loss: 0.3308 - val_accuracy: 0.8808\n",
      "Epoch 147/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8865 - val_loss: 0.3293 - val_accuracy: 0.8816\n",
      "Epoch 148/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3321 - accuracy: 0.8854 - val_loss: 0.3280 - val_accuracy: 0.8861\n",
      "Epoch 149/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8865 - val_loss: 0.3273 - val_accuracy: 0.8861\n",
      "Epoch 150/150\n",
      "334/334 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8865 - val_loss: 0.3274 - val_accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0e365d9a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiLayer = Sequential([\n",
    "    Input(shape=300, name='input_layer'),\n",
    "    Dense(75, activation='sigmoid', name='dense_layer1'),\n",
    "    Dense(4, activation='sigmoid', name='dense_layer2')\n",
    "])\n",
    "\n",
    "multiLayer.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "multiLayer.fit(train_X, train_Y, epochs=150, validation_data=(test_X,test_Y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fbe43e9b8e3a26ccf422ae77b5a9f6265d342f640ee5c983c29ad7ba809a2e8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('knock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
