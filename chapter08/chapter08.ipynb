{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a7f269",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279faff5",
   "metadata": {},
   "source": [
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6902f8",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8c5f1f",
   "metadata": {},
   "source": [
    "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．\n",
    "\n",
    "例えば，学習データについて，すべての事例$x_i$の特徴ベクトル$x_i$を並べた行列$X$と，正解ラベルを並べた行列（ベクトル）$Y$を作成したい．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d2df9",
   "metadata": {},
   "source": [
    "$$ \n",
    "X = \\begin{pmatrix} \n",
    "  \\boldsymbol{x}_1 \\\\ \n",
    "  \\boldsymbol{x}_2 \\\\ \n",
    "  \\dots \\\\ \n",
    "  \\boldsymbol{x}_n \\\\ \n",
    "\\end{pmatrix} \\in \\mathbb{R}^{n \\times d},\n",
    "Y = \\begin{pmatrix} \n",
    "  y_1 \\\\ \n",
    "  y_2 \\\\ \n",
    "  \\dots \\\\ \n",
    "  y_n \\\\ \n",
    "\\end{pmatrix} \\in \\mathbb{N}^{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0905e44c",
   "metadata": {},
   "source": [
    "ここで，$n$は学習データの事例数であり，$\\boldsymbol{x}_i \\in \\mathbb{R}^d$ と $y_i \\in \\mathbb{N}$ はそれぞれ，$i \\in \\{1, \\dots, n\\}$ 番目の事例の特徴量ベクトルと正解ラベルを表す． \n",
    "\n",
    "なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．\n",
    "\n",
    "$\\mathbb{N}_{<4}$ で $4$ 未満の自然数（$0$ を含む）を表すことにすれば，任意の事例の正解ラベル $y_i$ は $y_i \\in \\mathbb{N}_{<4}$ で表現できる． \n",
    "\n",
    "以降では，ラベルの種類数を $L$ で表す（今回の分類タスクでは $L=4$ である）．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713a49c",
   "metadata": {},
   "source": [
    "$i$ 番目の事例の特徴ベクトル $x_i$ は，次式で求める．\n",
    "\n",
    "$$\n",
    " \\boldsymbol{x}_i = \\frac{1}{T_i} \\sum_{t=1}^{T_i} \\mathrm{emb}(w_{i,t})\n",
    "$$ \n",
    "\n",
    "ここで，$i$ 番目の事例は $T_i$ 個の（記事見出しの）単語列 $ (w_{i,1}, w_{i,2}, \\dots, w_{i,T_i}) $ から構成され，$ \\mathrm{emb}(w) \\in \\mathbb{R}^d$ は単語 $w$ に対応する単語ベクトル（次元数は $d$ ）である．\n",
    "\n",
    "すなわち，$i$ 番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものが $x_i$ である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0153f25",
   "metadata": {},
   "source": [
    "今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．$300$ 次元の単語ベクトルを用いたので，$d=300$ である．\n",
    "\n",
    "$i$ 番目の事例のラベル $y_i$ は，次のように定義する．\n",
    "\n",
    "$$\n",
    "y_i = \\begin{cases}\n",
    "0 & (\\mbox{記事}x_i\\mbox{が「ビジネス」カテゴリの場合}) \\\\\n",
    "1 & (\\mbox{記事}x_i\\mbox{が「科学技術」カテゴリの場合}) \\\\\n",
    "2 & (\\mbox{記事}x_i\\mbox{が「エンターテイメント」カテゴリの場合}) \\\\\n",
    "3 & (\\mbox{記事}x_i\\mbox{が「健康」カテゴリの場合}) \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    " \n",
    "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf858b",
   "metadata": {},
   "source": [
    "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
    "\n",
    "学習データの特徴量行列: $ X_{\\rm train} \\in \\mathbb{R}^{N_t \\times d} $\n",
    "\n",
    "学習データのラベルベクトル: $ Y_{\\rm train} \\in \\mathbb{N}^{N_t} $\n",
    "\n",
    "検証データの特徴量行列: $ X_{\\rm valid} \\in \\mathbb{R}^{N_v \\times d} $\n",
    "\n",
    "検証データのラベルベクトル: $ Y_{\\rm valid} \\in \\mathbb{N}^{N_v} $\n",
    "\n",
    "評価データの特徴量行列: $ X_{\\rm test} \\in \\mathbb{R}^{N_e \\times d} $\n",
    "\n",
    "評価データのラベルベクトル: $ Y_{\\rm test} \\in \\mathbb{N}^{N_e} $\n",
    "\n",
    "なお，$N_t$, $N_v$, $N_e$ はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4324b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373fd324",
   "metadata": {},
   "source": [
    "問題50で構築した学習データ，検証データ，評価データをロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eccea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../chapter06/train.txt',sep='\\t')#,header=None)\n",
    "valid = pd.read_csv('../chapter06/valid.txt',sep='\\t')\n",
    "test = pd.read_csv('../chapter06/test.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4e2898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223786</td>\n",
       "      <td>US Stocks Advance as Small-Cap, Internet Share...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242050</td>\n",
       "      <td>Investors Couldn't Care Less About Data Breaches</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1154</td>\n",
       "      <td>Elephants really are intelligent: Creatures ca...</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197029</td>\n",
       "      <td>National Australia Bank 1st-half profit up 8.5...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159549</td>\n",
       "      <td>Green Bonds Could Cut Indian Clean-Energy Cost...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>414762</td>\n",
       "      <td>'They took center stage!' Sofia Vergara stuns ...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>104245</td>\n",
       "      <td>Selena Gomez Fires Her Parents: Heres Five Sta...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>314941</td>\n",
       "      <td>US housing finance regulator should consider s...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>344391</td>\n",
       "      <td>BNP Seeks Approval to Continue US Pension Busi...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>86459</td>\n",
       "      <td>Game Of Thrones Season Four, Episode One premi...</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              TITLE CATEGORY\n",
       "0         223786  US Stocks Advance as Small-Cap, Internet Share...        b\n",
       "1         242050   Investors Couldn't Care Less About Data Breaches        t\n",
       "2           1154  Elephants really are intelligent: Creatures ca...        t\n",
       "3         197029  National Australia Bank 1st-half profit up 8.5...        b\n",
       "4         159549  Green Bonds Could Cut Indian Clean-Energy Cost...        b\n",
       "...          ...                                                ...      ...\n",
       "1331      414762  'They took center stage!' Sofia Vergara stuns ...        e\n",
       "1332      104245  Selena Gomez Fires Her Parents: Heres Five Sta...        e\n",
       "1333      314941  US housing finance regulator should consider s...        b\n",
       "1334      344391  BNP Seeks Approval to Continue US Pension Busi...        b\n",
       "1335       86459  Game Of Thrones Season Four, Episode One premi...        e\n",
       "\n",
       "[1336 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6cedb1",
   "metadata": {},
   "source": [
    "タイトルを単語に分割したものと、正解ラベルを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db5a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['b', 't', 'e', 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5400d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b770546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be04a125",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abde7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    x = nlp.make_doc(x)\n",
    "    x = [d.text for d in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc605c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2add2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x = x.replace('.','') #ピリオド消す\n",
    "    x = x.replace(',','') #カンマ消す\n",
    "    x = x.replace(':','')\n",
    "    x = x.replace('?','')\n",
    "    x = x.replace('!','')\n",
    "    x = x.replace('\"','')\n",
    "    x = x.replace('-','')\n",
    "    \n",
    "    words = x.split(' ') #空白文字で区切る\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171fa0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbea8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_name):\n",
    "    #dataset = [line.split('\\t') for line in dataset_name] # [インデックス、タイトル、ラベル]\n",
    "    \n",
    "    # 単語に分割\n",
    "    dataset_x = dataset_name.iloc[:, 1]\n",
    "    dataset_x = [tokenize(line) for line in dataset_x]\n",
    "    #dataset_x = [tokenize(line[1]) for line in dataset_name]\n",
    "    # 正解ラベル\n",
    "    dataset_t = dataset_name.iloc[:, 2]\n",
    "    dataset_t = [categories.index(line) for line in dataset_t]\n",
    "    \n",
    "    return dataset_x, dataset_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c2ddfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_t = read_dataset(train)\n",
    "valid_x, valid_t = read_dataset(valid)\n",
    "test_x, test_t = read_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ab28465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Bulgaria's\",\n",
       "  'third',\n",
       "  'biggest',\n",
       "  'lender',\n",
       "  'says',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'on',\n",
       "  'operations'],\n",
       " ['Party',\n",
       "  'tents',\n",
       "  'go',\n",
       "  'up',\n",
       "  'on',\n",
       "  'the',\n",
       "  'eve',\n",
       "  'of',\n",
       "  'Jessica',\n",
       "  \"Simpson's\",\n",
       "  'wedding'],\n",
       " ['UK',\n",
       "  'shares',\n",
       "  'slide',\n",
       "  'on',\n",
       "  'China',\n",
       "  'growth',\n",
       "  'concerns',\n",
       "  'geopolitical',\n",
       "  'tension'],\n",
       " ['Scott',\n",
       "  'Derrickson',\n",
       "  'To',\n",
       "  'Direct',\n",
       "  'Dr',\n",
       "  'Strange',\n",
       "  '',\n",
       "  'Are',\n",
       "  'We',\n",
       "  'In',\n",
       "  'For',\n",
       "  'A',\n",
       "  'Darker',\n",
       "  'Marvel',\n",
       "  'Flick'],\n",
       " ['Obama',\n",
       "  'dedicates',\n",
       "  'National',\n",
       "  'September',\n",
       "  '11',\n",
       "  'Memorial',\n",
       "  'Museum',\n",
       "  'as',\n",
       "  \"'a\",\n",
       "  'sacred',\n",
       "  'place',\n",
       "  '',\n",
       "  '']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3e4c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 0, 2, 2]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fe94268678b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(train_t[:5])\n",
    "print(train_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c69cf5",
   "metadata": {},
   "source": [
    "単語ベクトルとして，問題60でダウンロードしたものを用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d537ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('../chapter07/data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae4231",
   "metadata": {},
   "source": [
    "train_x, valid_x, test_x を特徴ベクトル mtrain_v, valid_v, test_v に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b3c3f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6010fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vector(words):\n",
    "    lst = [torch.tensor(model[w]) for w in words if w in model]\n",
    "    \n",
    "    if len(lst)==0:\n",
    "        print(words)\n",
    "\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def dataset_to_vector(dataset):\n",
    "    return torch.stack([sent_to_vector(words) for words in dataset]) # words : タイトルの単語リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3ff14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c6c1ac",
   "metadata": {},
   "source": [
    "下だめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9646c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_vector(dataset):\n",
    "    x, y = [], []\n",
    "    \n",
    "    for data in dataset:\n",
    "                    \n",
    "        x = (np.array([model[w] for w in data if w in model]))\n",
    "        \n",
    "        if np.sum(x) == 0:\n",
    "            x = np.zeros((1, 300))\n",
    "            \n",
    "        # fx.write(\" \".join([str(i) for i in list(x.mean(axis=0))]) + \"\\n\"\n",
    "        # fy.write(str(category[tmp[0]]) + \"\\n\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5ab14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a811fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_v = dataset_to_vector(train_x)\n",
    "valid_v = dataset_to_vector(valid_x)\n",
    "test_v = dataset_to_vector(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54dd09db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10684, 300])\n",
      "tensor([ 7.3785e-02, -6.3388e-02,  7.5711e-02,  4.1701e-02,  2.1023e-04,\n",
      "        -1.1049e-01,  5.1175e-02, -4.1450e-02,  1.5218e-01,  5.2985e-02,\n",
      "        -3.3230e-03, -7.1730e-02,  1.9511e-02,  7.0584e-02, -1.0632e-01,\n",
      "        -9.3257e-03,  5.1765e-02, -4.6007e-02, -1.5815e-02, -1.8214e-02,\n",
      "         1.9033e-02,  2.8911e-03, -3.3285e-02,  6.2113e-02,  1.5086e-02,\n",
      "        -3.9117e-02, -6.0303e-02,  4.0744e-02, -2.6367e-02,  9.0617e-02,\n",
      "         9.6300e-04, -4.4723e-02,  5.0602e-02,  4.9127e-02, -2.0616e-02,\n",
      "        -2.5906e-03, -3.5225e-02,  4.8898e-02,  1.2040e-01,  4.8564e-02,\n",
      "         3.8089e-02, -1.5744e-01,  7.8444e-02,  1.9314e-02, -2.8364e-02,\n",
      "        -2.0501e-02,  2.2169e-02,  1.6832e-02, -6.2500e-02,  1.5215e-02,\n",
      "         3.1359e-02,  2.5762e-02,  9.4944e-05,  4.5878e-02, -4.1714e-02,\n",
      "        -4.9344e-02, -1.3718e-01,  5.4742e-02,  6.2120e-03, -1.3562e-01,\n",
      "        -7.0801e-02,  4.9045e-02, -7.1669e-02, -6.7383e-02, -5.5135e-02,\n",
      "        -1.7359e-02,  1.1643e-01,  3.9469e-02, -3.9066e-02,  5.5739e-02,\n",
      "         4.1148e-02, -4.4569e-02,  6.4165e-02,  3.6608e-02, -1.1698e-01,\n",
      "        -2.8408e-02,  6.9390e-02,  7.5473e-02,  9.7046e-03,  8.7077e-02,\n",
      "        -3.2260e-02, -1.1060e-01,  3.7842e-02,  5.5698e-02, -5.9962e-02,\n",
      "        -1.0005e-01, -1.5324e-01,  1.0990e-01,  6.2995e-02,  2.3126e-02,\n",
      "         1.2061e-01, -3.0596e-02, -2.7930e-02, -4.8726e-02, -1.0910e-01,\n",
      "        -1.5192e-01,  5.8078e-02, -7.2835e-02, -1.8948e-02,  1.7931e-02,\n",
      "        -1.0308e-03, -2.3695e-02, -3.2267e-02, -1.7877e-02,  2.6801e-02,\n",
      "         3.7638e-02,  2.5947e-02, -5.3423e-02,  4.5898e-02, -1.3754e-01,\n",
      "         9.4835e-02, -6.8841e-02, -4.3525e-02, -5.9428e-02, -2.9989e-02,\n",
      "        -1.8529e-02,  1.2831e-02,  4.6577e-02,  1.9640e-01,  1.0341e-01,\n",
      "        -1.0471e-01,  2.5106e-02, -4.8509e-02,  1.6938e-01,  4.2440e-02,\n",
      "        -5.5773e-02,  9.6775e-03, -5.5040e-02, -7.0048e-02,  4.4542e-02,\n",
      "        -4.0222e-02, -5.2504e-02, -5.7556e-02, -1.1363e-01, -2.2529e-02,\n",
      "        -1.3312e-01,  5.6749e-02,  3.6282e-02, -5.9530e-02, -3.0192e-02,\n",
      "         4.7418e-02, -1.6627e-01,  6.7225e-02,  1.0735e-01,  5.3684e-02,\n",
      "        -3.3936e-02, -2.3336e-02,  4.2494e-02, -4.8655e-02,  1.7509e-02,\n",
      "         4.6332e-02,  1.0010e-02,  5.9706e-02, -1.5462e-03, -5.3872e-03,\n",
      "         9.5927e-03, -6.4311e-02, -8.1584e-03, -2.7154e-02,  3.8059e-02,\n",
      "        -3.9944e-02,  8.4235e-02,  4.2657e-02, -4.6746e-02, -1.3401e-02,\n",
      "        -3.2074e-02,  1.9992e-02, -2.3268e-02,  2.4251e-02, -5.2246e-02,\n",
      "        -6.8054e-02, -1.2343e-03,  7.4829e-02, -1.0033e-01, -1.1882e-02,\n",
      "        -4.6372e-02,  1.4028e-01, -8.2838e-02, -7.1465e-02, -4.2664e-02,\n",
      "        -1.0167e-01, -1.2740e-01,  1.9090e-03,  1.9650e-02, -6.9417e-02,\n",
      "        -2.0372e-02,  1.5984e-02,  6.8441e-02,  5.7504e-02,  1.4133e-01,\n",
      "        -1.2273e-01, -1.4628e-02, -5.1832e-02,  8.8921e-02, -1.3997e-02,\n",
      "        -8.1380e-04, -8.5030e-02, -3.3396e-02, -4.0765e-02, -2.5277e-01,\n",
      "         9.4604e-04,  5.1643e-02,  3.7191e-02,  2.8266e-02, -4.1009e-02,\n",
      "         9.8253e-02,  6.4356e-02, -3.5536e-03,  3.7950e-02, -2.6849e-02,\n",
      "        -6.7309e-02, -1.3102e-02, -1.4106e-02,  6.4969e-02, -3.2518e-02,\n",
      "         1.2655e-02,  5.2022e-02,  2.5319e-02, -2.6584e-03, -6.7315e-02,\n",
      "         4.0961e-02,  6.3260e-02, -1.7008e-02, -1.1068e-02, -4.5817e-02,\n",
      "        -5.5089e-02,  1.0973e-02,  1.0877e-01,  4.2697e-02, -1.6046e-02,\n",
      "         8.7823e-03, -4.5912e-03, -1.2722e-02,  2.6367e-02,  8.3123e-02,\n",
      "        -1.5761e-02,  1.0625e-01, -1.3193e-01,  6.4562e-03, -7.0970e-03,\n",
      "         2.1471e-02, -4.4994e-02, -6.0635e-02, -4.7750e-02,  6.4752e-02,\n",
      "        -6.5670e-02, -9.5113e-03, -9.1646e-03,  8.7755e-02, -1.0031e-01,\n",
      "         3.1942e-03, -4.3928e-02, -2.8415e-02,  2.3220e-02,  5.8363e-02,\n",
      "        -1.4079e-02,  8.4226e-02,  6.4046e-02, -3.5577e-02, -6.1849e-03,\n",
      "        -1.1661e-02, -4.6326e-02,  5.3556e-02,  9.8755e-02,  6.3043e-02,\n",
      "         3.5550e-02, -9.3167e-02, -5.9652e-02, -1.1747e-01,  4.4047e-02,\n",
      "        -2.4231e-02,  8.1991e-02,  1.0352e-01, -2.8554e-02, -4.7024e-02,\n",
      "        -4.9995e-02, -1.2199e-01, -7.7094e-02, -3.7381e-02, -4.2250e-02,\n",
      "        -2.4007e-02,  1.0018e-01,  3.0084e-02,  4.6790e-02,  1.3462e-02,\n",
      "         4.1829e-02, -5.0502e-02,  4.7390e-02,  2.9433e-03,  3.4339e-02,\n",
      "        -1.0307e-01,  3.0450e-02, -1.1161e-01,  1.0064e-02,  1.7225e-02,\n",
      "         3.2271e-02, -5.1202e-02, -1.5055e-02,  4.8489e-02, -9.2265e-02])\n"
     ]
    }
   ],
   "source": [
    "print(train_v.shape)\n",
    "print(train_v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c380d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd3406e",
   "metadata": {},
   "source": [
    "pickleで保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a596caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5d33cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = torch.tensor(train_t).long()\n",
    "valid_t = torch.tensor(valid_t).long()\n",
    "test_t = torch.tensor(test_t).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ebef0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0,  ..., 0, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67c85f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.feature.pickle', 'wb') as f:\n",
    "    pickle.dump(train_v, f)\n",
    "with open('data/train.label.pickle', 'wb') as f:\n",
    "    pickle.dump(train_t, f)\n",
    "\n",
    "with open('data/valid.feature.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_v, f)\n",
    "with open('data/valid.label.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_t, f)\n",
    "\n",
    "with open('data/test.feature.pickle', 'wb') as f:\n",
    "    pickle.dump(test_v, f)\n",
    "with open('data/test.label.pickle', 'wb') as f:\n",
    "    pickle.dump(test_t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ade45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec892f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe9714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "751b5b7f",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f3cae",
   "metadata": {},
   "source": [
    "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b62395",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\boldsymbol{y}}_1 = {\\rm softmax}(\\boldsymbol{x}_1 W), \\\\\n",
    "\\hat{Y} = {\\rm softmax}(X_{[1:4]} W)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a30f6f",
   "metadata": {},
   "source": [
    "ただし，$softmax$ はソフトマックス関数，$ X_{[1:4]} \\in \\mathbb{R}^{4 \\times d} $ は特徴ベクトル$x_1$, $x_2$, $x_3$, $x_4$ を縦に並べた行列である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0d2bb",
   "metadata": {},
   "source": [
    "$$\n",
    "X_{[1:4]} = \\begin{pmatrix} \n",
    "  \\boldsymbol{x}_1 \\\\ \n",
    "  \\boldsymbol{x}_2 \\\\ \n",
    "  \\boldsymbol{x}_3 \\\\ \n",
    "  \\boldsymbol{x}_4 \\\\ \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99466e4e",
   "metadata": {},
   "source": [
    "行列 $ W \\in \\mathbb{R}^{d \\times L} $ は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．\n",
    "\n",
    "なお，$ \\hat{\\boldsymbol{y}}_1 \\in \\mathbb{R}^L $ は未学習の行列 $W$ で事例 $x_1$ を分類したときに，各カテゴリに属する確率を表すベクトルである． \n",
    "\n",
    "同様に，$ \\hat{Y} \\in \\mathbb{R}^{n \\times L} $ は，学習データの事例 $x_1$,$x_2$,$x_3$,$x_4$ について，各カテゴリに属する確率を行列として表現している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "472d6330",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10684, 300])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徴ベクトル\n",
    "train_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8807ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10684])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa31804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "710bca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(input_size, output_size, bias = False)\n",
    "        torch.nn.init.xavier_normal_(self.fc.weight) # 単層ニューラルネットワークの重み行列はランダムな値で初期化\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fedc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(300, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c20c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7e9e4bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0738, -0.0634,  0.0757,  ..., -0.0151,  0.0485, -0.0923],\n",
       "        [ 0.0486, -0.0027, -0.0415,  ..., -0.0585,  0.0446,  0.0276],\n",
       "        [ 0.0182,  0.0247, -0.0247,  ..., -0.0096,  0.1365, -0.0576],\n",
       "        ...,\n",
       "        [-0.0355,  0.0380,  0.0113,  ..., -0.0848,  0.0651, -0.0568],\n",
       "        [-0.0112,  0.0212, -0.0893,  ...,  0.0403,  0.0788,  0.0139],\n",
       "        [ 0.1577,  0.0992, -0.1321,  ..., -0.0760, -0.0445, -0.0994]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db4f9306",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10684, 300])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60ba72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abb06c73",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{\\boldsymbol{y}}_1 = {\\rm softmax}(\\boldsymbol{x}_1 W) \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c687cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3122, 0.2391, 0.2280, 0.2207], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(train_v[0])\n",
    "y = torch.softmax(y, dim=-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201d567c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{Y} = {\\rm softmax}(X_{[1:4]} W) \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab976ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3122, 0.2391, 0.2280, 0.2207],\n",
       "        [0.2569, 0.2761, 0.2102, 0.2567],\n",
       "        [0.2945, 0.2397, 0.2079, 0.2580],\n",
       "        [0.2662, 0.2601, 0.2318, 0.2419]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = model(train_v[:4])\n",
    "Y = torch.softmax(Y, dim=-1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63190ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a3425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75bbbb67",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4a656",
   "metadata": {},
   "source": [
    "学習データの事例 $x_1$ と事例集合 $x_1$,$x_2$,$x_3$,$x_4$ に対して，クロスエントロピー損失と，行列 $W$ に対する勾配を計算せよ．\n",
    "\n",
    "なお，ある事例$x_i$に対して損失は次式で計算される．\n",
    "\n",
    "$$\n",
    "l_i = - \\log [\\mbox{事例}x_i\\mbox{が}y_i\\mbox{に分類される確率}]\n",
    "$$\n",
    "\n",
    "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acfb4e4",
   "metadata": {},
   "source": [
    "学習データの事例  $x_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4657d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef1fe417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "損失 : 1.1641709804534912\n",
      "勾配\n",
      "tensor([[-0.0508,  0.0436, -0.0521,  ...,  0.0104, -0.0334,  0.0635],\n",
      "        [ 0.0176, -0.0152,  0.0181,  ..., -0.0036,  0.0116, -0.0221],\n",
      "        [ 0.0168, -0.0145,  0.0173,  ..., -0.0034,  0.0111, -0.0210],\n",
      "        [ 0.0163, -0.0140,  0.0167,  ..., -0.0033,  0.0107, -0.0204]])\n"
     ]
    }
   ],
   "source": [
    "y = model(train_v[:1])\n",
    "t = train_t[:1]\n",
    "\n",
    "loss = criterion(y, t)\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "print('損失 :', loss.item())\n",
    "print('勾配')\n",
    "print(model.fc.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b12e6e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.zero_grad()\n",
    "model.fc.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49474161",
   "metadata": {},
   "source": [
    "事例集合 $x_1$, $x_2$, $x_3$,  $x_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab96e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "損失 : 1.352078914642334\n",
      "勾配\n",
      "tensor([[-0.0109,  0.0113, -0.0103,  ...,  0.0002, -0.0232,  0.0240],\n",
      "        [ 0.0107,  0.0023,  0.0012,  ..., -0.0058,  0.0203, -0.0107],\n",
      "        [-0.0099, -0.0160,  0.0083,  ...,  0.0112, -0.0172, -0.0028],\n",
      "        [ 0.0101,  0.0024,  0.0008,  ..., -0.0055,  0.0201, -0.0105]])\n"
     ]
    }
   ],
   "source": [
    "y = model(train_v[:4])\n",
    "t = train_t[:4]\n",
    "\n",
    "loss = criterion(y, t)\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "print('損失 :', loss.item())\n",
    "print('勾配')\n",
    "print(model.fc.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcb4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d685141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12519f31",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f33bda",
   "metadata": {},
   "source": [
    "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列 $W$ を学習せよ．\n",
    "\n",
    "なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a803c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "091155dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac875f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(300, 4),\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671a16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e728b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d67876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10684])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71998933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10684])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a1eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0153cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a842a6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\tloss\n",
      "1\t4289.4180\n",
      "2\t3175.0735\n",
      "3\t2950.5535\n",
      "4\t2833.9585\n",
      "5\t2740.6562\n",
      "6\t2688.7427\n",
      "7\t2643.5425\n",
      "8\t2599.5818\n",
      "9\t2579.4985\n",
      "10\t2556.8745\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "ds = TensorDataset(train_v, train_t)\n",
    "\n",
    "\n",
    "# DataLoaderを作成\n",
    "loader = DataLoader(ds, batch_size=1, shuffle=True)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.net.parameters(), lr=1e-1)\n",
    "\n",
    "num_epochs = 10\n",
    "print(\"epoch\\tloss\")\n",
    "for epoch in range(num_epochs):\n",
    "    sum_loss = 0\n",
    "    for x, y in loader:\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss\n",
    "    print(f\"{epoch+1}\\t{sum_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78610e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f623e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14db8ac8",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9ab88",
   "metadata": {},
   "source": [
    "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acc856a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "    label = label.data.numpy()\n",
    "    \n",
    "    return (pred == label).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be17caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データでの正解率 : 0.9215649569449644\n"
     ]
    }
   ],
   "source": [
    "pred = model(train_v)\n",
    "print('学習データでの正解率 :', accuracy(pred, train_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8040d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "評価データでの正解率 : 0.906437125748503\n"
     ]
    }
   ],
   "source": [
    "pred = model(valid_v)\n",
    "print('評価データでの正解率 :', accuracy(pred, valid_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0924b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80fe86be",
   "metadata": {},
   "source": [
    "## 75. 損失と正解率のプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7f275",
   "metadata": {},
   "source": [
    "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874101cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33183995",
   "metadata": {},
   "source": [
    "## 76. チェックポイント"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e9695",
   "metadata": {},
   "source": [
    "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afa7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8f2ab07",
   "metadata": {},
   "source": [
    "## 77. ミニバッチ化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e9307",
   "metadata": {},
   "source": [
    "問題76のコードを改変し，$B$ 事例ごとに損失・勾配を計算し，行列 $W$ の値を更新せよ（ミニバッチ化）．\n",
    "\n",
    "$B$ の値を $ 1, 2, 4, 8, \\dots $ と変化させながら，1エポックの学習に要する時間を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316e90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "401b43ff",
   "metadata": {},
   "source": [
    "## 78. GPU上での学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be130ede",
   "metadata": {},
   "source": [
    "問題77のコードを改変し，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994099a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b90a470a",
   "metadata": {},
   "source": [
    "## 79. 多層ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642c034",
   "metadata": {},
   "source": [
    "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63766a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
