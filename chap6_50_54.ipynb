{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58a3820",
   "metadata": {},
   "source": [
    "### 50. データの入手・整形\n",
    "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
    "\n",
    "1. ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
    "2. 情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
    "3. 抽出された事例をランダムに並び替える．\n",
    "4. 抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．\n",
    "\n",
    "学習データと評価データを作成したら，各カテゴリの事例数を確認せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962b8f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba78671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a42c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読込\n",
    "# readme.txtに書いてあったフォーマット:ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n",
    "df = pd.read_csv('./newsCorpora_re.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
    "# pd.read_csv:csvファイルを読み込む　(読み込むファイル名,ヘッダ行の有無,区切るとこ,名前)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc279ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの抽出\n",
    "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
    "# loc:特定の値を含むデータを抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c6ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
    "# (入力データ, 入力データサンプルの割合（比率）を表す,シャッフル,中身を固定,分類の目的変数を指定し偏りが生じないようにする )\n",
    "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63eea303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "# タブくぎり\n",
    "train.to_csv('./train.txt', sep='\\t', index=False)\n",
    "valid.to_csv('./valid.txt', sep='\\t', index=False)\n",
    "test.to_csv('./test.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af6c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【学習データ】\n",
      "b    4501\n",
      "e    4235\n",
      "t    1220\n",
      "m     728\n",
      "Name: CATEGORY, dtype: int64\n",
      "【検証データ】\n",
      "b    563\n",
      "e    529\n",
      "t    153\n",
      "m     91\n",
      "Name: CATEGORY, dtype: int64\n",
      "【評価データ】\n",
      "b    563\n",
      "e    530\n",
      "t    152\n",
      "m     91\n",
      "Name: CATEGORY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 事例数の確認\n",
    "print('【学習データ】')\n",
    "print(train['CATEGORY'].value_counts())\n",
    "print('【検証データ】')\n",
    "print(valid['CATEGORY'].value_counts())\n",
    "print('【評価データ】')\n",
    "print(test['CATEGORY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9d9a8",
   "metadata": {},
   "source": [
    "### 51. 特徴量抽出\n",
    "学習データ，検証データ，評価データから特徴量を抽出し，それぞれtrain.feature.txt，valid.feature.txt，test.feature.txtというファイル名で保存せよ． なお，カテゴリ分類に有用そうな特徴量は各自で自由に設計せよ．記事の見出しを単語列に変換したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f6ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量はTF-IDFを用いる\n",
    "# TF-IDE:各文書中に含まれる各単語が「その文書内でどれくらい重要か」を表す尺度\n",
    "\n",
    "#テキストの前処理\n",
    "import string #文字列操作\n",
    "import re #正規表現操作\n",
    "\n",
    "def preprocessing(text):\n",
    "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    text = text.translate(table)  # 記号をスペースに置換\n",
    "    text = text.lower()  # 小文字化\n",
    "    text = re.sub('[0-9]+', '0', text)  # 数字列を0に置換\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102ae0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               TITLE CATEGORY\n",
      "0  refile update 0 european car sales up for sixt...        b\n",
      "1  amazon plans to fight ftc over mobile app purc...        t\n",
      "2  kids still get codeine in emergency rooms desp...        m\n",
      "3  what on earth happened between solange and jay...        e\n",
      "4  nato missile defense is flight tested over hawaii        b\n"
     ]
    }
   ],
   "source": [
    "# データの再結合\n",
    "df = pd.concat([train, valid, test], axis=0) # axis:縦横どちらで連結するか 0は縦\n",
    "df.reset_index(drop=True, inplace=True)  # indexを振りなおす\n",
    "# drop:元のindexを削除\n",
    "# inplace:元のオブジェクトを変更\n",
    "\n",
    "# 前処理の実施（見出し）\n",
    "df['TITLE'] = df['TITLE'].map(lambda x: preprocessing(x))\n",
    "# map(関数, シーケンス)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadedd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0m  0million  0nd   0s  0st  0th  0th birthday   aa  aaliyah  abbvie  ...  \\\n",
      "0  0.0       0.0  0.0  0.0  0.0  0.0           0.0  0.0      0.0     0.0  ...   \n",
      "1  0.0       0.0  0.0  0.0  0.0  0.0           0.0  0.0      0.0     0.0  ...   \n",
      "2  0.0       0.0  0.0  0.0  0.0  0.0           0.0  0.0      0.0     0.0  ...   \n",
      "3  0.0       0.0  0.0  0.0  0.0  0.0           0.0  0.0      0.0     0.0  ...   \n",
      "4  0.0       0.0  0.0  0.0  0.0  0.0           0.0  0.0      0.0     0.0  ...   \n",
      "\n",
      "   young  your  your mother   yr  yr high  yuan  zac  zac efron  zendaya  zone  \n",
      "0    0.0   0.0          0.0  0.0      0.0   0.0  0.0        0.0      0.0   0.0  \n",
      "1    0.0   0.0          0.0  0.0      0.0   0.0  0.0        0.0      0.0   0.0  \n",
      "2    0.0   0.0          0.0  0.0      0.0   0.0  0.0        0.0      0.0   0.0  \n",
      "3    0.0   0.0          0.0  0.0      0.0   0.0  0.0        0.0      0.0   0.0  \n",
      "4    0.0   0.0          0.0  0.0      0.0   0.0  0.0        0.0      0.0   0.0  \n",
      "\n",
      "[5 rows x 2815 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# データの分割\n",
    "train_valid = df[:len(train) + len(valid)]\n",
    "test = df[len(train) + len(valid):]\n",
    "\n",
    "# TfidfVectorizer\n",
    "vec_tfidf = TfidfVectorizer(min_df=10, ngram_range=(1, 2))  # ngram_rangeでTF-IDFを計算する単語の長さを指定\n",
    "\n",
    "# ベクトル化\n",
    "X_train_valid = vec_tfidf.fit_transform(train_valid['TITLE'])  # testの情報は使わない\n",
    "X_test = vec_tfidf.transform(test['TITLE'])\n",
    "\n",
    "# ベクトルをデータフレームに変換\n",
    "X_train_valid = pd.DataFrame(X_train_valid.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "X_test = pd.DataFrame(X_test.toarray(), columns=vec_tfidf.get_feature_names())\n",
    "\n",
    "# データの分割\n",
    "X_train = X_train_valid[:len(train)]\n",
    "X_valid = X_train_valid[len(train):]\n",
    "\n",
    "# データの保存\n",
    "X_train.to_csv('./X_train.txt', sep='\\t', index=False)\n",
    "X_valid.to_csv('./X_valid.txt', sep='\\t', index=False)\n",
    "X_test.to_csv('./X_test.txt', sep='\\t', index=False)\n",
    "\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72ae7f",
   "metadata": {},
   "source": [
    "### 52. 学習\n",
    "51で構築した学習データを用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14c7ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=123)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# モデルの学習\n",
    "lg = LogisticRegression(random_state=123, max_iter=10000)\n",
    "lg.fit(X_train, train['CATEGORY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2504b",
   "metadata": {},
   "source": [
    "### 53. 予測\n",
    "52で学習したロジスティック回帰モデルを用い，与えられた記事見出しからカテゴリとその予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9eb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.8402797 , 0.67904346, 0.55638924, ..., 0.86051034, 0.6135933 ,\n",
      "       0.90828244]), array(['b', 't', 'm', ..., 'b', 'm', 'e'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score_lg(lg, X):\n",
    "    return [np.max(lg.predict_proba(X), axis=1), lg.predict(X)]\n",
    "\n",
    "train_pred = score_lg(lg, X_train)\n",
    "test_pred = score_lg(lg, X_test)\n",
    "\n",
    "print(train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342315f",
   "metadata": {},
   "source": [
    "### 54. 正解率の計測\n",
    "52で学習したロジスティック回帰モデルの正解率を，学習データおよび評価データ上で計測せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91efffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率（学習データ）：0.927\n",
      "正解率（評価データ）：0.885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_accuracy = accuracy_score(train['CATEGORY'], train_pred[1])\n",
    "test_accuracy = accuracy_score(test['CATEGORY'], test_pred[1])\n",
    "print(f'正解率（学習データ）：{train_accuracy:.3f}')\n",
    "print(f'正解率（評価データ）：{test_accuracy:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
